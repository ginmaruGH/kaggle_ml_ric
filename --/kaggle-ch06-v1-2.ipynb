{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b41d30f1",
   "metadata": {
    "papermill": {
     "duration": 0.025574,
     "end_time": "2024-02-14T12:55:00.212684",
     "exception": false,
     "start_time": "2024-02-14T12:55:00.187110",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2024/02/14更新\n",
    "- 書籍発売後にライブラリのバージョンアップが生じたため、書籍のコードが一部動作しなくなりました\n",
    "- このため、書籍のコードが動作するようにコードを一部変更\n",
    "    - 変更を最小化するため、基本的には書籍に合わせてライブラリをダウングレード\n",
    "    - 名称変更となったライブラリは最新のライブラリ名に変更\n",
    "- なお、一部ですが、2024/02/14時点の最新ライブラリでも動作するコードをコメントアウトで同じセルに参考までに掲載しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ef762c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:55:00.267098Z",
     "iopub.status.busy": "2024-02-14T12:55:00.266701Z",
     "iopub.status.idle": "2024-02-14T12:56:04.679587Z",
     "shell.execute_reply": "2024-02-14T12:56:04.678458Z"
    },
    "papermill": {
     "duration": 64.443102,
     "end_time": "2024-02-14T12:56:04.682340",
     "exception": false,
     "start_time": "2024-02-14T12:55:00.239238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.3.5\r\n",
      "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from pandas==1.3.5) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.10/site-packages (from pandas==1.3.5) (2023.3.post1)\r\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==1.3.5) (1.24.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.16.0)\r\n",
      "Installing collected packages: pandas\r\n",
      "  Attempting uninstall: pandas\r\n",
      "    Found existing installation: pandas 2.2.0\r\n",
      "    Uninstalling pandas-2.2.0:\r\n",
      "      Successfully uninstalled pandas-2.2.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "arviz 0.17.0 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.0.11 which is incompatible.\r\n",
      "esda 2.5.1 requires pandas>1.4, but you have pandas 1.3.5 which is incompatible.\r\n",
      "featuretools 1.28.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\r\n",
      "geopandas 0.14.2 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires pandas>=1.4, but you have pandas 1.3.5 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "mapclassify 2.6.1 requires pandas!=1.5.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "osmnx 1.8.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\r\n",
      "spopt 0.6.0 requires pandas!=1.5.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "woodwork 0.27.0 requires pandas>=1.4.3, but you have pandas 1.3.5 which is incompatible.\r\n",
      "xarray 2024.1.0 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "xarray 2024.1.0 requires pandas>=1.5, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed pandas-1.3.5\r\n",
      "Collecting lightgbm==3.3.1\r\n",
      "  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from lightgbm==3.3.1) (0.42.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from lightgbm==3.3.1) (1.24.4)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from lightgbm==3.3.1) (1.11.4)\r\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /opt/conda/lib/python3.10/site-packages (from lightgbm==3.3.1) (1.2.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.1) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn!=0.22.0->lightgbm==3.3.1) (3.2.0)\r\n",
      "Installing collected packages: lightgbm\r\n",
      "  Attempting uninstall: lightgbm\r\n",
      "    Found existing installation: lightgbm 4.2.0\r\n",
      "    Uninstalling lightgbm-4.2.0:\r\n",
      "      Successfully uninstalled lightgbm-4.2.0\r\n",
      "Successfully installed lightgbm-3.3.1\r\n",
      "Collecting scikit-learn==1.0.2\r\n",
      "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.6 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.24.4)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.11.4)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.3.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.0.2) (3.2.0)\r\n",
      "Installing collected packages: scikit-learn\r\n",
      "  Attempting uninstall: scikit-learn\r\n",
      "    Found existing installation: scikit-learn 1.2.2\r\n",
      "    Uninstalling scikit-learn-1.2.2:\r\n",
      "      Successfully uninstalled scikit-learn-1.2.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "esda 2.5.1 requires pandas>1.4, but you have pandas 1.3.5 which is incompatible.\r\n",
      "mapclassify 2.6.1 requires pandas!=1.5.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\r\n",
      "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.3.5 which is incompatible.\r\n",
      "spopt 0.6.0 requires pandas!=1.5.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\r\n",
      "spopt 0.6.0 requires scikit-learn>=1.1, but you have scikit-learn 1.0.2 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "woodwork 0.27.0 requires pandas>=1.4.3, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.0.2\r\n"
     ]
    }
   ],
   "source": [
    "# 引数が大きく変更されているため、ダウングレードで対応\n",
    "# 最初に実行してください。\n",
    "!pip install pandas==1.3.5\n",
    "!pip install lightgbm==3.3.1\n",
    "!pip install scikit-learn==1.0.2\n",
    "\n",
    "# なお、LightGBMの最新版ではCallbackが使われており、過去バージョンと大きく書き方が変化。最新版を使い方を知りたい場合は公式ページを参照してください。\n",
    "# https://lightgbm.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83c998",
   "metadata": {
    "papermill": {
     "duration": 0.03207,
     "end_time": "2024-02-14T12:56:04.748098",
     "exception": false,
     "start_time": "2024-02-14T12:56:04.716028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Kaggleで磨く 機械学習の実践力\n",
    "# 第6章 モデルチューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fca4315",
   "metadata": {
    "papermill": {
     "duration": 0.031524,
     "end_time": "2024-02-14T12:56:04.811162",
     "exception": false,
     "start_time": "2024-02-14T12:56:04.779638",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.1 LightGBMのハイパーパラメータのチューニング\n",
    "## 6.1.2 ハイパーパラメータの自動チューニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1788e",
   "metadata": {
    "papermill": {
     "duration": 0.031239,
     "end_time": "2024-02-14T12:56:04.874150",
     "exception": false,
     "start_time": "2024-02-14T12:56:04.842911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト: ライブラリのインポート (スクリプト4-1の再掲)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "564a0837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:56:04.942004Z",
     "iopub.status.busy": "2024-02-14T12:56:04.941557Z",
     "iopub.status.idle": "2024-02-14T12:56:13.341369Z",
     "shell.execute_reply": "2024-02-14T12:56:13.339932Z"
    },
    "papermill": {
     "duration": 8.437287,
     "end_time": "2024-02-14T12:56:13.344484",
     "exception": false,
     "start_time": "2024-02-14T12:56:04.907197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "# 分布確認\n",
    "# import pandas_profiling as pdp\n",
    "import ydata_profiling as pdp # ライブラリ名称が変更になったため\n",
    "\n",
    "# 可視化\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 前処理\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# バリデーション\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, GroupKFold\n",
    "\n",
    "# 評価指標\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# モデリング: lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793f5ce7",
   "metadata": {
    "papermill": {
     "duration": 0.032342,
     "end_time": "2024-02-14T12:56:13.411048",
     "exception": false,
     "start_time": "2024-02-14T12:56:13.378706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト: ファイルの読み込み (スクリプト4-2の再掲)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994556f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:56:13.477026Z",
     "iopub.status.busy": "2024-02-14T12:56:13.476625Z",
     "iopub.status.idle": "2024-02-14T12:56:13.492985Z",
     "shell.execute_reply": "2024-02-14T12:56:13.492074Z"
    },
    "papermill": {
     "duration": 0.052107,
     "end_time": "2024-02-14T12:56:13.495709",
     "exception": false,
     "start_time": "2024-02-14T12:56:13.443602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9832187c",
   "metadata": {
    "papermill": {
     "duration": 0.031195,
     "end_time": "2024-02-14T12:56:13.560865",
     "exception": false,
     "start_time": "2024-02-14T12:56:13.529670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト: データセット作成 (スクリプト4-8の再掲)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2638d9e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:56:13.626848Z",
     "iopub.status.busy": "2024-02-14T12:56:13.625658Z",
     "iopub.status.idle": "2024-02-14T12:56:13.637579Z",
     "shell.execute_reply": "2024-02-14T12:56:13.636374Z"
    },
    "papermill": {
     "duration": 0.047684,
     "end_time": "2024-02-14T12:56:13.640210",
     "exception": false,
     "start_time": "2024-02-14T12:56:13.592526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 2) (891, 1) (891, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, id_train = df_train[[\"Pclass\", \"Fare\"]], \\\n",
    "                             df_train[[\"Survived\"]], \\\n",
    "                             df_train[[\"PassengerId\"]]\n",
    "print(x_train.shape, y_train.shape, id_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f268078",
   "metadata": {
    "papermill": {
     "duration": 0.03322,
     "end_time": "2024-02-14T12:56:13.775620",
     "exception": false,
     "start_time": "2024-02-14T12:56:13.742400",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-1: optunaのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e719dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:56:13.841445Z",
     "iopub.status.busy": "2024-02-14T12:56:13.840651Z",
     "iopub.status.idle": "2024-02-14T12:56:15.222928Z",
     "shell.execute_reply": "2024-02-14T12:56:15.221819Z"
    },
    "papermill": {
     "duration": 1.417912,
     "end_time": "2024-02-14T12:56:15.225511",
     "exception": false,
     "start_time": "2024-02-14T12:56:13.807599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e20ad5",
   "metadata": {
    "papermill": {
     "duration": 0.03098,
     "end_time": "2024-02-14T12:56:15.288394",
     "exception": false,
     "start_time": "2024-02-14T12:56:15.257414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-2: 目的関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246fa8f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:56:15.359753Z",
     "iopub.status.busy": "2024-02-14T12:56:15.358107Z",
     "iopub.status.idle": "2024-02-14T12:56:15.376790Z",
     "shell.execute_reply": "2024-02-14T12:56:15.374900Z"
    },
    "papermill": {
     "duration": 0.059926,
     "end_time": "2024-02-14T12:56:15.380778",
     "exception": false,
     "start_time": "2024-02-14T12:56:15.320852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 探索しないハイパーパラメータ\n",
    "params_base = {\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    'n_estimators': 100000,\n",
    "    \"bagging_freq\": 1,\n",
    "    \"seed\": 123,\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "    # 探索するハイパーパラメータ\n",
    "    params_tuning = {\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 8, 256),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 5, 200),\n",
    "        \"min_sum_hessian_in_leaf\": trial.suggest_float(\"min_sum_hessian_in_leaf\", 1e-5, 1e-2, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.5, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.5, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-2, 1e2, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-2, 1e2, log=True),\n",
    "    }\n",
    "    params_tuning.update(params_base)\n",
    "    \n",
    "    # モデル学習・評価\n",
    "    list_metrics = []\n",
    "    cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x_train, y_train))\n",
    "    for nfold in np.arange(5):\n",
    "        idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "        x_tr, y_tr = x_train.loc[idx_tr, :], y_train.loc[idx_tr, :]\n",
    "        x_va, y_va = x_train.loc[idx_va, :], y_train.loc[idx_va, :]\n",
    "        model = lgb.LGBMClassifier(**params_tuning)\n",
    "        model.fit(x_tr,\n",
    "                  y_tr,\n",
    "                  eval_set=[(x_tr,y_tr), (x_va,y_va)],\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose=0,\n",
    "                 )\n",
    "#         # 2024/02/14環境で動かしたい場合はこのコードを利用してください。\n",
    "#         model.fit(x_tr,\n",
    "#                   y_tr,\n",
    "#                   eval_set=[(x_tr,y_tr), (x_va,y_va)],\n",
    "#                   callbacks=[\n",
    "#                       lgb.early_stopping(stopping_rounds=100, verbose=True),\n",
    "#                       lgb.log_evaluation(0),\n",
    "#                   ],\n",
    "#                  )\n",
    "        \n",
    "        y_va_pred = model.predict_proba(x_va)[:,1]\n",
    "        metric_va = accuracy_score(y_va, np.where(y_va_pred>=0.5, 1, 0))\n",
    "        list_metrics.append(metric_va)\n",
    "    \n",
    "    # 評価値の計算\n",
    "    metrics = np.mean(list_metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab36e22",
   "metadata": {
    "papermill": {
     "duration": 0.03115,
     "end_time": "2024-02-14T12:56:15.453203",
     "exception": false,
     "start_time": "2024-02-14T12:56:15.422053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-3: 最適化処理（探索の実行）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b06c857",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-02-14T12:56:15.519448Z",
     "iopub.status.busy": "2024-02-14T12:56:15.518670Z",
     "iopub.status.idle": "2024-02-14T12:57:16.172045Z",
     "shell.execute_reply": "2024-02-14T12:57:16.170988Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 60.689396,
     "end_time": "2024-02-14T12:57:16.174579",
     "exception": false,
     "start_time": "2024-02-14T12:56:15.485183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:15,523] A new study created in memory with name: no-name-7006dc18-ca31-4eff-b0a4-2e2b586d8ce3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.492522233779106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.492522233779106\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8597344848927815, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8597344848927815\n",
      "[LightGBM] [Warning] lambda_l2 is set=83.76388146302445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=83.76388146302445\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7756573845414456, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7756573845414456\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=4.792414358623587e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=4.792414358623587e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:18,499] Trial 0 finished with value: 0.664478061640826 and parameters: {'num_leaves': 181, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 4.792414358623587e-05, 'feature_fraction': 0.7756573845414456, 'bagging_fraction': 0.8597344848927815, 'lambda_l1': 0.492522233779106, 'lambda_l2': 83.76388146302445}. Best is trial 0 with value: 0.664478061640826.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.567922374174008, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.567922374174008\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8645248536920208, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8645248536920208\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.01732652966363563, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01732652966363563\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6715890080754348, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6715890080754348\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00015009027543233888, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00015009027543233888\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=99, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=99\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:20,010] Trial 1 finished with value: 0.6712196346745339 and parameters: {'num_leaves': 178, 'min_data_in_leaf': 99, 'min_sum_hessian_in_leaf': 0.00015009027543233888, 'feature_fraction': 0.6715890080754348, 'bagging_fraction': 0.8645248536920208, 'lambda_l1': 0.567922374174008, 'lambda_l2': 0.01732652966363563}. Best is trial 1 with value: 0.6712196346745339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.3406343673102123, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3406343673102123\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7657756869209191, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7657756869209191\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.4482904089131434, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4482904089131434\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5877258780737462, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5877258780737462\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=3.52756635172055e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=3.52756635172055e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=149, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=149\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:21,622] Trial 2 finished with value: 0.65762350134957 and parameters: {'num_leaves': 107, 'min_data_in_leaf': 149, 'min_sum_hessian_in_leaf': 3.52756635172055e-05, 'feature_fraction': 0.5877258780737462, 'bagging_fraction': 0.7657756869209191, 'lambda_l1': 1.3406343673102123, 'lambda_l2': 3.4482904089131434}. Best is trial 1 with value: 0.6712196346745339.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2799978022399009, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2799978022399009\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6614794569265892, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6614794569265892\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.08185645330667264, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08185645330667264\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8612216912851107, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8612216912851107\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0006808799287054756, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0006808799287054756\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=146, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=146\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:23,360] Trial 3 finished with value: 0.6722302429226037 and parameters: {'num_leaves': 219, 'min_data_in_leaf': 146, 'min_sum_hessian_in_leaf': 0.0006808799287054756, 'feature_fraction': 0.8612216912851107, 'bagging_fraction': 0.6614794569265892, 'lambda_l1': 0.2799978022399009, 'lambda_l2': 0.08185645330667264}. Best is trial 3 with value: 0.6722302429226037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.9434967110751797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9434967110751797\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7154313816648219, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7154313816648219\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5050346330980694, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5050346330980694\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7168505863397641, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7168505863397641\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.889360449174926e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.889360449174926e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=128, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=128\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:24,575] Trial 4 finished with value: 0.668972443663298 and parameters: {'num_leaves': 81, 'min_data_in_leaf': 128, 'min_sum_hessian_in_leaf': 1.889360449174926e-05, 'feature_fraction': 0.7168505863397641, 'bagging_fraction': 0.7154313816648219, 'lambda_l1': 0.9434967110751797, 'lambda_l2': 0.5050346330980694}. Best is trial 3 with value: 0.6722302429226037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.1319282717196035, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.1319282717196035\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7509183379421682, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7509183379421682\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.029005047452739414, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.029005047452739414\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9720800091019398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9720800091019398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004788147156768277, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004788147156768277\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=88, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=88\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:26,092] Trial 5 finished with value: 0.6587847592743706 and parameters: {'num_leaves': 85, 'min_data_in_leaf': 88, 'min_sum_hessian_in_leaf': 0.004788147156768277, 'feature_fraction': 0.9720800091019398, 'bagging_fraction': 0.7509183379421682, 'lambda_l1': 3.1319282717196035, 'lambda_l2': 0.029005047452739414}. Best is trial 3 with value: 0.6722302429226037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:26,459] Trial 6 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 87, 'min_data_in_leaf': 86, 'min_sum_hessian_in_leaf': 0.003971252247766701, 'feature_fraction': 0.6252276826982534, 'bagging_fraction': 0.7415171321313522, 'lambda_l1': 87.54657140659076, 'lambda_l2': 1.1965765212602313}. Best is trial 3 with value: 0.6722302429226037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=87.54657140659076, reg_alpha=0.0 will be ignored. Current value: lambda_l1=87.54657140659076\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7415171321313522, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7415171321313522\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.1965765212602313, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1965765212602313\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6252276826982534, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6252276826982534\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.003971252247766701, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.003971252247766701\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=86, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=86\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.23499322154972468, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.23499322154972468\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7725340032332324, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7725340032332324\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1646202117975735, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1646202117975735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8015300642054637, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8015300642054637\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0030131614432849746, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0030131614432849746\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:29,989] Trial 7 finished with value: 0.6992530286862093 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.0030131614432849746, 'feature_fraction': 0.8015300642054637, 'bagging_fraction': 0.7725340032332324, 'lambda_l1': 0.23499322154972468, 'lambda_l2': 0.1646202117975735}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.206714812711709, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.206714812711709\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8346568914811361, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8346568914811361\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.1594683442464033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1594683442464033\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7552111687390055, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7552111687390055\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00423029374725911, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00423029374725911\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:31,907] Trial 8 finished with value: 0.6823363254033017 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 138, 'min_sum_hessian_in_leaf': 0.00423029374725911, 'feature_fraction': 0.7552111687390055, 'bagging_fraction': 0.8346568914811361, 'lambda_l1': 2.206714812711709, 'lambda_l2': 3.1594683442464033}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.05982625838323253, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.05982625838323253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6218331872684371, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6218331872684371\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9490717640641542, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9490717640641542\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8818414207216692, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8818414207216692\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=1.7765808030254076e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=1.7765808030254076e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=170, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=170\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:32,912] Trial 9 finished with value: 0.6362751867428285 and parameters: {'num_leaves': 175, 'min_data_in_leaf': 170, 'min_sum_hessian_in_leaf': 1.7765808030254076e-05, 'feature_fraction': 0.8818414207216692, 'bagging_fraction': 0.6218331872684371, 'lambda_l1': 0.05982625838323253, 'lambda_l2': 1.9490717640641542}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010612397212799423, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010612397212799423\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9940542446575642, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9940542446575642\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.1661409929489422, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1661409929489422\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5040305717020102, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5040305717020102\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0009194171614722974, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0009194171614722974\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:36,185] Trial 10 finished with value: 0.673435440336451 and parameters: {'num_leaves': 32, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.0009194171614722974, 'feature_fraction': 0.5040305717020102, 'bagging_fraction': 0.9940542446575642, 'lambda_l1': 0.010612397212799423, 'lambda_l2': 0.1661409929489422}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:36,957] Trial 11 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 141, 'min_data_in_leaf': 198, 'min_sum_hessian_in_leaf': 0.009951069387483545, 'feature_fraction': 0.7991399603154743, 'bagging_fraction': 0.8761275059380933, 'lambda_l1': 8.895512707730266, 'lambda_l2': 11.692356850069807}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8.895512707730266, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.895512707730266\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8761275059380933, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8761275059380933\n",
      "[LightGBM] [Warning] lambda_l2 is set=11.692356850069807, reg_lambda=0.0 will be ignored. Current value: lambda_l2=11.692356850069807\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7991399603154743, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7991399603154743\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.009951069387483545, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.009951069387483545\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09349295720311095, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09349295720311095\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5595408581248553, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5595408581248553\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.2669531355707319, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.2669531355707319\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8476730378212194, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8476730378212194\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.001634914743632515, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.001634914743632515\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=18, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=18\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:42,259] Trial 12 finished with value: 0.6802083987194777 and parameters: {'num_leaves': 255, 'min_data_in_leaf': 18, 'min_sum_hessian_in_leaf': 0.001634914743632515, 'feature_fraction': 0.8476730378212194, 'bagging_fraction': 0.5595408581248553, 'lambda_l1': 0.09349295720311095, 'lambda_l2': 0.2669531355707319}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=15.027486795162927, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15.027486795162927\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9474999290561824, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9474999290561824\n",
      "[LightGBM] [Warning] lambda_l2 is set=16.04887249986447, reg_lambda=0.0 will be ignored. Current value: lambda_l2=16.04887249986447\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9479314162009256, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9479314162009256\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0021756690901938718, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0021756690901938718\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=43, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=43\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:43,660] Trial 13 finished with value: 0.6712196346745339 and parameters: {'num_leaves': 140, 'min_data_in_leaf': 43, 'min_sum_hessian_in_leaf': 0.0021756690901938718, 'feature_fraction': 0.9479314162009256, 'bagging_fraction': 0.9474999290561824, 'lambda_l1': 15.027486795162927, 'lambda_l2': 16.04887249986447}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10302449045855197, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10302449045855197\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8148189817022143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8148189817022143\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.1467516807077525, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.1467516807077525\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7214624501496751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7214624501496751\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0002511161117887837, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0002511161117887837\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=60, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=60\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:45,818] Trial 14 finished with value: 0.6846400100433118 and parameters: {'num_leaves': 31, 'min_data_in_leaf': 60, 'min_sum_hessian_in_leaf': 0.0002511161117887837, 'feature_fraction': 0.7214624501496751, 'bagging_fraction': 0.8148189817022143, 'lambda_l1': 0.10302449045855197, 'lambda_l2': 7.1467516807077525}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.026008451540619953, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.026008451540619953\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8032054077767327, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8032054077767327\n",
      "[LightGBM] [Warning] lambda_l2 is set=12.21210843043782, reg_lambda=0.0 will be ignored. Current value: lambda_l2=12.21210843043782\n",
      "[LightGBM] [Warning] feature_fraction is set=0.690460596426745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.690460596426745\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00023305225408823253, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00023305225408823253\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=46, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=46\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:47,626] Trial 15 finished with value: 0.6745904211913878 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 46, 'min_sum_hessian_in_leaf': 0.00023305225408823253, 'feature_fraction': 0.690460596426745, 'bagging_fraction': 0.8032054077767327, 'lambda_l1': 0.026008451540619953, 'lambda_l2': 12.21210843043782}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.14515159340667338, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.14515159340667338\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6677912738306708, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6677912738306708\n",
      "[LightGBM] [Warning] lambda_l2 is set=34.66806840700916, reg_lambda=0.0 will be ignored. Current value: lambda_l2=34.66806840700916\n",
      "[LightGBM] [Warning] feature_fraction is set=0.816763159679514, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.816763159679514\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00014054556930505904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00014054556930505904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=65, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=65\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:49,397] Trial 16 finished with value: 0.6778858828698764 and parameters: {'num_leaves': 41, 'min_data_in_leaf': 65, 'min_sum_hessian_in_leaf': 0.00014054556930505904, 'feature_fraction': 0.816763159679514, 'bagging_fraction': 0.6677912738306708, 'lambda_l1': 0.14515159340667338, 'lambda_l2': 34.66806840700916}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.03426707576896973, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.03426707576896973\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5002172961009613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5002172961009613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04837506886369723, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04837506886369723\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6231218216909848, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6231218216909848\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00041942600526778174, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00041942600526778174\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=28, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=28\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:51,808] Trial 17 finished with value: 0.6801393509509761 and parameters: {'num_leaves': 48, 'min_data_in_leaf': 28, 'min_sum_hessian_in_leaf': 0.00041942600526778174, 'feature_fraction': 0.6231218216909848, 'bagging_fraction': 0.5002172961009613, 'lambda_l1': 0.03426707576896973, 'lambda_l2': 0.04837506886369723}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.18409793634935437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.18409793634935437\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9432358972978486, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9432358972978486\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.42463135597338925, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.42463135597338925\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9236171148088437, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9236171148088437\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=7.90220458942919e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=7.90220458942919e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=61, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=61\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:55,658] Trial 18 finished with value: 0.6790848032138597 and parameters: {'num_leaves': 218, 'min_data_in_leaf': 61, 'min_sum_hessian_in_leaf': 7.90220458942919e-05, 'feature_fraction': 0.9236171148088437, 'bagging_fraction': 0.9432358972978486, 'lambda_l1': 0.18409793634935437, 'lambda_l2': 0.42463135597338925}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010045321756357375, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010045321756357375\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.805029885015916, subsample=1.0 will be ignored. Current value: bagging_fraction=0.805029885015916\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0995890378098838, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0995890378098838\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7302924887036465, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7302924887036465\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004165592806968668, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004165592806968668\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=113, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=113\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:56,914] Trial 19 finished with value: 0.6622308706295901 and parameters: {'num_leaves': 160, 'min_data_in_leaf': 113, 'min_sum_hessian_in_leaf': 0.0004165592806968668, 'feature_fraction': 0.7302924887036465, 'bagging_fraction': 0.805029885015916, 'lambda_l1': 0.010045321756357375, 'lambda_l2': 0.0995890378098838}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.3216819410872765, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3216819410872765\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6900582768491921, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6900582768491921\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.9453451423419853, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9453451423419853\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5306298908707103, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5306298908707103\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0013845801360137025, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0013845801360137025\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=35, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=35\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:56:59,513] Trial 20 finished with value: 0.6745904211913879 and parameters: {'num_leaves': 209, 'min_data_in_leaf': 35, 'min_sum_hessian_in_leaf': 0.0013845801360137025, 'feature_fraction': 0.5306298908707103, 'bagging_fraction': 0.6900582768491921, 'lambda_l1': 0.3216819410872765, 'lambda_l2': 0.9453451423419853}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.445630241563508, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.445630241563508\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8140984986812078, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8140984986812078\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.156916351584709, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.156916351584709\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7668244440376193, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7668244440376193\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.008748025832898368, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.008748025832898368\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=73, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=73\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:02,054] Trial 21 finished with value: 0.6667252526520621 and parameters: {'num_leaves': 106, 'min_data_in_leaf': 73, 'min_sum_hessian_in_leaf': 0.008748025832898368, 'feature_fraction': 0.7668244440376193, 'bagging_fraction': 0.8140984986812078, 'lambda_l1': 3.445630241563508, 'lambda_l2': 4.156916351584709}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.1127374904866487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.1127374904866487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8886750178544316, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8886750178544316\n",
      "[LightGBM] [Warning] lambda_l2 is set=4.554403222246632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.554403222246632\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7482688842343571, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7482688842343571\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.004061668550970804, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.004061668550970804\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=129, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=129\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:03,676] Trial 22 finished with value: 0.6644152909421882 and parameters: {'num_leaves': 62, 'min_data_in_leaf': 129, 'min_sum_hessian_in_leaf': 0.004061668550970804, 'feature_fraction': 0.7482688842343571, 'bagging_fraction': 0.8886750178544316, 'lambda_l1': 2.1127374904866487, 'lambda_l2': 4.554403222246632}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:04,731] Trial 23 finished with value: 0.6453141673466826 and parameters: {'num_leaves': 111, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 0.0026312807570427793, 'feature_fraction': 0.6773917561139398, 'bagging_fraction': 0.8221198194153576, 'lambda_l1': 8.59982035475244, 'lambda_l2': 0.7542908028826634}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=8.59982035475244, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.59982035475244\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8221198194153576, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8221198194153576\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7542908028826634, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7542908028826634\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6773917561139398, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6773917561139398\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0026312807570427793, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0026312807570427793\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=6, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.054062737213373784, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054062737213373784\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9137850613244668, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9137850613244668\n",
      "[LightGBM] [Warning] lambda_l2 is set=7.254429610183551, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.254429610183551\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8193477007279062, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8193477007279062\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007958826711101101, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007958826711101101\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=164, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=164\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:06,632] Trial 24 finished with value: 0.6823488795430293 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 164, 'min_sum_hessian_in_leaf': 0.0007958826711101101, 'feature_fraction': 0.8193477007279062, 'bagging_fraction': 0.9137850613244668, 'lambda_l1': 0.054062737213373784, 'lambda_l2': 7.254429610183551}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.04052688745892243, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04052688745892243\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9096697647298414, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9096697647298414\n",
      "[LightGBM] [Warning] lambda_l2 is set=33.56741330161014, reg_lambda=0.0 will be ignored. Current value: lambda_l2=33.56741330161014\n",
      "[LightGBM] [Warning] feature_fraction is set=0.897993229060577, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.897993229060577\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0007220208410542904, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0007220208410542904\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=176, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=176\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:08,197] Trial 25 finished with value: 0.6599836796183542 and parameters: {'num_leaves': 21, 'min_data_in_leaf': 176, 'min_sum_hessian_in_leaf': 0.0007220208410542904, 'feature_fraction': 0.897993229060577, 'bagging_fraction': 0.9096697647298414, 'lambda_l1': 0.04052688745892243, 'lambda_l2': 33.56741330161014}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.07242256998354961, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.07242256998354961\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.777469997490065, subsample=1.0 will be ignored. Current value: bagging_fraction=0.777469997490065\n",
      "[LightGBM] [Warning] lambda_l2 is set=6.818961945625027, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.818961945625027\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8168240033302105, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8168240033302105\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.00019985545118893227, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.00019985545118893227\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=49, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=49\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:11,787] Trial 26 finished with value: 0.6757140166970059 and parameters: {'num_leaves': 63, 'min_data_in_leaf': 49, 'min_sum_hessian_in_leaf': 0.00019985545118893227, 'feature_fraction': 0.8168240033302105, 'bagging_fraction': 0.777469997490065, 'lambda_l1': 0.07242256998354961, 'lambda_l2': 6.818961945625027}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.13213697905758195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.13213697905758195\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9245894599408239, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9245894599408239\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9898087013583565, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9898087013583565\n",
      "[LightGBM] [Warning] feature_fraction is set=0.832859028154117, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.832859028154117\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0011015177430549305, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0011015177430549305\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=110, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=110\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:13,910] Trial 27 finished with value: 0.6700207143305505 and parameters: {'num_leaves': 9, 'min_data_in_leaf': 110, 'min_sum_hessian_in_leaf': 0.0011015177430549305, 'feature_fraction': 0.832859028154117, 'bagging_fraction': 0.9245894599408239, 'lambda_l1': 0.13213697905758195, 'lambda_l2': 1.9898087013583565}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:14,740] Trial 28 finished with value: 0.6161634548992531 and parameters: {'num_leaves': 54, 'min_data_in_leaf': 169, 'min_sum_hessian_in_leaf': 0.0004463850369701868, 'feature_fraction': 0.7818076921940365, 'bagging_fraction': 0.7239926057056618, 'lambda_l1': 0.26894380562875153, 'lambda_l2': 82.43363076639685}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.26894380562875153, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.26894380562875153\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7239926057056618, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7239926057056618\n",
      "[LightGBM] [Warning] lambda_l2 is set=82.43363076639685, reg_lambda=0.0 will be ignored. Current value: lambda_l2=82.43363076639685\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7818076921940365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7818076921940365\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.0004463850369701868, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.0004463850369701868\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=169, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=169\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.02276315503480073, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02276315503480073\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9850169158486759, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9850169158486759\n",
      "[LightGBM] [Warning] lambda_l2 is set=32.318206202200265, reg_lambda=0.0 will be ignored. Current value: lambda_l2=32.318206202200265\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7116385045852216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7116385045852216\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=8.505644215173895e-05, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=8.505644215173895e-05\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=196, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=196\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-14 12:57:16,166] Trial 29 finished with value: 0.6587470968551881 and parameters: {'num_leaves': 161, 'min_data_in_leaf': 196, 'min_sum_hessian_in_leaf': 8.505644215173895e-05, 'feature_fraction': 0.7116385045852216, 'bagging_fraction': 0.9850169158486759, 'lambda_l1': 0.02276315503480073, 'lambda_l2': 32.318206202200265}. Best is trial 7 with value: 0.6992530286862093.\n"
     ]
    }
   ],
   "source": [
    "sampler = optuna.samplers.TPESampler(seed=123)\n",
    "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0f7da",
   "metadata": {
    "papermill": {
     "duration": 0.049025,
     "end_time": "2024-02-14T12:57:16.272144",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.223119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-4: 探索結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e48b082a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:16.372438Z",
     "iopub.status.busy": "2024-02-14T12:57:16.371402Z",
     "iopub.status.idle": "2024-02-14T12:57:16.381356Z",
     "shell.execute_reply": "2024-02-14T12:57:16.380183Z"
    },
    "papermill": {
     "duration": 0.063234,
     "end_time": "2024-02-14T12:57:16.383795",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.320561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(best)=0.6993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 160,\n",
       " 'min_data_in_leaf': 28,\n",
       " 'min_sum_hessian_in_leaf': 0.0030131614432849746,\n",
       " 'feature_fraction': 0.8015300642054637,\n",
       " 'bagging_fraction': 0.7725340032332324,\n",
       " 'lambda_l1': 0.23499322154972468,\n",
       " 'lambda_l2': 0.1646202117975735}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(\"acc(best)={:.4f}\".format(trial.value))\n",
    "display(trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912f3030",
   "metadata": {
    "papermill": {
     "duration": 0.049835,
     "end_time": "2024-02-14T12:57:16.484088",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.434253",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-5: ベストなハイパーパラメータの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a53ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:16.585704Z",
     "iopub.status.busy": "2024-02-14T12:57:16.585286Z",
     "iopub.status.idle": "2024-02-14T12:57:16.593140Z",
     "shell.execute_reply": "2024-02-14T12:57:16.592066Z"
    },
    "papermill": {
     "duration": 0.062092,
     "end_time": "2024-02-14T12:57:16.595352",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.533260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_leaves': 160,\n",
       " 'min_data_in_leaf': 28,\n",
       " 'min_sum_hessian_in_leaf': 0.0030131614432849746,\n",
       " 'feature_fraction': 0.8015300642054637,\n",
       " 'bagging_fraction': 0.7725340032332324,\n",
       " 'lambda_l1': 0.23499322154972468,\n",
       " 'lambda_l2': 0.1646202117975735,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'learning_rate': 0.02,\n",
       " 'n_estimators': 100000,\n",
       " 'bagging_freq': 1,\n",
       " 'seed': 123}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params_best = trial.params\n",
    "params_best.update(params_base)\n",
    "display(params_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcdd63f",
   "metadata": {
    "papermill": {
     "duration": 0.049184,
     "end_time": "2024-02-14T12:57:16.695388",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.646204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.2 LightGBM以外のモデル利用\n",
    "## 6.2.1 scikit-learnの各種モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a57483",
   "metadata": {
    "papermill": {
     "duration": 0.048952,
     "end_time": "2024-02-14T12:57:16.794003",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.745051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Titanicデータを用いた例：ロジスティック回帰\n",
    "#### スクリプト6-6: ファイル読み込みとデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa3f42ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:16.894798Z",
     "iopub.status.busy": "2024-02-14T12:57:16.894411Z",
     "iopub.status.idle": "2024-02-14T12:57:16.908545Z",
     "shell.execute_reply": "2024-02-14T12:57:16.907251Z"
    },
    "papermill": {
     "duration": 0.067453,
     "end_time": "2024-02-14T12:57:16.911385",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.843932",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6683f2bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:17.013335Z",
     "iopub.status.busy": "2024-02-14T12:57:17.012906Z",
     "iopub.status.idle": "2024-02-14T12:57:17.024144Z",
     "shell.execute_reply": "2024-02-14T12:57:17.022887Z"
    },
    "papermill": {
     "duration": 0.06567,
     "end_time": "2024-02-14T12:57:17.026674",
     "exception": false,
     "start_time": "2024-02-14T12:57:16.961004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Age         177\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 欠損値の確認\n",
    "x_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b114b4ae",
   "metadata": {
    "papermill": {
     "duration": 0.050855,
     "end_time": "2024-02-14T12:57:17.131554",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.080699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-7: 欠損値の補間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290a4706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:17.234566Z",
     "iopub.status.busy": "2024-02-14T12:57:17.233166Z",
     "iopub.status.idle": "2024-02-14T12:57:17.242570Z",
     "shell.execute_reply": "2024-02-14T12:57:17.241400Z"
    },
    "papermill": {
     "duration": 0.064259,
     "end_time": "2024-02-14T12:57:17.245390",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.181131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間：数値データ\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 欠損値補間：カテゴリ変数\n",
    "x_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4f6c1a",
   "metadata": {
    "papermill": {
     "duration": 0.052395,
     "end_time": "2024-02-14T12:57:17.349477",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.297082",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-8: カテゴリ変数の数値化（one-hot-encoding）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e77d5dfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:17.451148Z",
     "iopub.status.busy": "2024-02-14T12:57:17.450720Z",
     "iopub.status.idle": "2024-02-14T12:57:17.467060Z",
     "shell.execute_reply": "2024-02-14T12:57:17.465866Z"
    },
    "papermill": {
     "duration": 0.069603,
     "end_time": "2024-02-14T12:57:17.469883",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.400280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train[[\"Embarked\"]])\n",
    "df_embarked = pd.DataFrame(\n",
    "    ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n",
    "    columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\n",
    "\n",
    "x_train = pd.concat([x_train, df_embarked], axis=1)\n",
    "x_train = x_train.drop(columns=[\"Embarked\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bca5b9",
   "metadata": {
    "papermill": {
     "duration": 0.04881,
     "end_time": "2024-02-14T12:57:17.568228",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.519418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-9: 数値データの正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "842a2bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:17.669620Z",
     "iopub.status.busy": "2024-02-14T12:57:17.669195Z",
     "iopub.status.idle": "2024-02-14T12:57:17.677899Z",
     "shell.execute_reply": "2024-02-14T12:57:17.676825Z"
    },
    "papermill": {
     "duration": 0.062075,
     "end_time": "2024-02-14T12:57:17.680202",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.618127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train[\"Pclass\"] = (x_train[\"Pclass\"] -x_train[\"Pclass\"].min()) / (x_train[\"Pclass\"].max() - x_train[\"Pclass\"].min()) \n",
    "x_train[\"Age\"] = (x_train[\"Age\"] -x_train[\"Age\"].min()) / (x_train[\"Age\"].max() - x_train[\"Age\"].min()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5486a",
   "metadata": {
    "papermill": {
     "duration": 0.05211,
     "end_time": "2024-02-14T12:57:17.782862",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.730752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-10: 学習データと検証データの分割（ホールドアウト検証）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f05cf1d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:17.884070Z",
     "iopub.status.busy": "2024-02-14T12:57:17.883654Z",
     "iopub.status.idle": "2024-02-14T12:57:17.900778Z",
     "shell.execute_reply": "2024-02-14T12:57:17.899679Z"
    },
    "papermill": {
     "duration": 0.070415,
     "end_time": "2024-02-14T12:57:17.903445",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.833030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b654b9",
   "metadata": {
    "papermill": {
     "duration": 0.048979,
     "end_time": "2024-02-14T12:57:18.002107",
     "exception": false,
     "start_time": "2024-02-14T12:57:17.953128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-11: LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22282adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:18.104637Z",
     "iopub.status.busy": "2024-02-14T12:57:18.104209Z",
     "iopub.status.idle": "2024-02-14T12:57:18.151002Z",
     "shell.execute_reply": "2024-02-14T12:57:18.149425Z"
    },
    "papermill": {
     "duration": 0.102963,
     "end_time": "2024-02-14T12:57:18.154908",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.051945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7263\n",
      "[0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_logis = LogisticRegression()\n",
    "\n",
    "# 学習\n",
    "model_logis.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_logis.predict(x_va)\n",
    "print(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\n",
    "print(y_va_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbd2514",
   "metadata": {
    "papermill": {
     "duration": 0.049722,
     "end_time": "2024-02-14T12:57:18.255685",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.205963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-12: 確率値の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96f8d15d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:18.357387Z",
     "iopub.status.busy": "2024-02-14T12:57:18.356950Z",
     "iopub.status.idle": "2024-02-14T12:57:18.367388Z",
     "shell.execute_reply": "2024-02-14T12:57:18.366407Z"
    },
    "papermill": {
     "duration": 0.065287,
     "end_time": "2024-02-14T12:57:18.370193",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.304906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83621285 0.16378715]\n",
      " [0.23058311 0.76941689]\n",
      " [0.83244141 0.16755859]\n",
      " [0.32227072 0.67772928]\n",
      " [0.62569522 0.37430478]]\n"
     ]
    }
   ],
   "source": [
    "y_va_pred_proba = model_logis.predict_proba(x_va)\n",
    "print(y_va_pred_proba[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3bf1ff",
   "metadata": {
    "papermill": {
     "duration": 0.049302,
     "end_time": "2024-02-14T12:57:18.469225",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.419923",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Titanicデータを用いた例：SVM\n",
    "#### スクリプト6-13: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7567d109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:18.570959Z",
     "iopub.status.busy": "2024-02-14T12:57:18.570570Z",
     "iopub.status.idle": "2024-02-14T12:57:18.688853Z",
     "shell.execute_reply": "2024-02-14T12:57:18.686954Z"
    },
    "papermill": {
     "duration": 0.172296,
     "end_time": "2024-02-14T12:57:18.691544",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.519248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.7151\n",
      "[0 1 0 1 0]\n",
      "[[0.73985924 0.26014076]\n",
      " [0.28242534 0.71757466]\n",
      " [0.73986177 0.26013823]\n",
      " [0.26828214 0.73171786]\n",
      " [0.58950192 0.41049808]]\n"
     ]
    }
   ],
   "source": [
    "# モデル定義\n",
    "from sklearn.svm import SVC\n",
    "model_svm = SVC(C=1.0, random_state=123, probability=True)\n",
    "\n",
    "# 学習\n",
    "model_svm.fit(x_tr, y_tr)\n",
    "\n",
    "# 予測\n",
    "y_va_pred = model_svm.predict(x_va)\n",
    "print(\"accuracy:{:.4f}\".format(accuracy_score(y_va, y_va_pred)))\n",
    "print(y_va_pred[:5])\n",
    "\n",
    "# 確率値の取得\n",
    "y_va_pred_proba = model_svm.predict_proba(x_va)\n",
    "print(y_va_pred_proba[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39133a1",
   "metadata": {
    "papermill": {
     "duration": 0.051277,
     "end_time": "2024-02-14T12:57:18.792432",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.741155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6.2.2 ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e05a79",
   "metadata": {
    "papermill": {
     "duration": 0.05263,
     "end_time": "2024-02-14T12:57:18.895423",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.842793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### ニューラルネットワークの適用例：①全結合層のみのネットワークモデル\n",
    "#### スクリプト6-14: ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4df7fc99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:18.998155Z",
     "iopub.status.busy": "2024-02-14T12:57:18.997422Z",
     "iopub.status.idle": "2024-02-14T12:57:35.175435Z",
     "shell.execute_reply": "2024-02-14T12:57:35.174101Z"
    },
    "papermill": {
     "duration": 16.23305,
     "end_time": "2024-02-14T12:57:35.178405",
     "exception": false,
     "start_time": "2024-02-14T12:57:18.945355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 12:57:21.602077: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-14 12:57:21.602277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-14 12:57:21.794351: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0828dfa7",
   "metadata": {
    "papermill": {
     "duration": 0.050145,
     "end_time": "2024-02-14T12:57:35.280265",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.230120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-15: tensorflowの再現性のためのシード指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc77878",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:35.395071Z",
     "iopub.status.busy": "2024-02-14T12:57:35.393915Z",
     "iopub.status.idle": "2024-02-14T12:57:35.404454Z",
     "shell.execute_reply": "2024-02-14T12:57:35.403237Z"
    },
    "papermill": {
     "duration": 0.076786,
     "end_time": "2024-02-14T12:57:35.406916",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.330130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    session_conf = tf.compat.v1.ConfigProto(\n",
    "        intra_op_parallelism_threads=1,\n",
    "        inter_op_parallelism_threads=1\n",
    "    )\n",
    "    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "    tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622e65ba",
   "metadata": {
    "papermill": {
     "duration": 0.049653,
     "end_time": "2024-02-14T12:57:35.511642",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.461989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-16: ファイルの読み込みとデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9511d898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:35.611465Z",
     "iopub.status.busy": "2024-02-14T12:57:35.611056Z",
     "iopub.status.idle": "2024-02-14T12:57:35.624010Z",
     "shell.execute_reply": "2024-02-14T12:57:35.623136Z"
    },
    "papermill": {
     "duration": 0.065843,
     "end_time": "2024-02-14T12:57:35.626623",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.560780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Embarked\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5bafc5",
   "metadata": {
    "papermill": {
     "duration": 0.049392,
     "end_time": "2024-02-14T12:57:35.726639",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.677247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-17: 数値データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5a7532a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:35.828577Z",
     "iopub.status.busy": "2024-02-14T12:57:35.827706Z",
     "iopub.status.idle": "2024-02-14T12:57:35.836444Z",
     "shell.execute_reply": "2024-02-14T12:57:35.835555Z"
    },
    "papermill": {
     "duration": 0.062914,
     "end_time": "2024-02-14T12:57:35.838979",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.776065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 正規化\n",
    "for col in [\"Pclass\", \"Age\"]:\n",
    "    value_min = x_train[col].min()\n",
    "    value_max = x_train[col].max()\n",
    "    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e749002",
   "metadata": {
    "papermill": {
     "duration": 0.049215,
     "end_time": "2024-02-14T12:57:35.938243",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.889028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-18: カテゴリ変数の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "163aac2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:36.039170Z",
     "iopub.status.busy": "2024-02-14T12:57:36.038545Z",
     "iopub.status.idle": "2024-02-14T12:57:36.051620Z",
     "shell.execute_reply": "2024-02-14T12:57:36.050737Z"
    },
    "papermill": {
     "duration": 0.06625,
     "end_time": "2024-02-14T12:57:36.054167",
     "exception": false,
     "start_time": "2024-02-14T12:57:35.987917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Embarked\"] = x_train[\"Embarked\"].fillna(x_train[\"Embarked\"].mode()[0])\n",
    "\n",
    "# one-hot-encoding\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(x_train[[\"Embarked\"]])\n",
    "df_embarked = pd.DataFrame(ohe.transform(x_train[[\"Embarked\"]]).toarray(), \n",
    "                           columns=[\"Embarked_{}\".format(col) for col in ohe.categories_[0]])\n",
    "x_train = pd.concat([x_train.drop(columns=[\"Embarked\"]), \n",
    "                     df_embarked], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc73e3",
   "metadata": {
    "papermill": {
     "duration": 0.049318,
     "end_time": "2024-02-14T12:57:36.154551",
     "exception": false,
     "start_time": "2024-02-14T12:57:36.105233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-19: 学習データと検証データの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "905933d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:36.255217Z",
     "iopub.status.busy": "2024-02-14T12:57:36.254567Z",
     "iopub.status.idle": "2024-02-14T12:57:36.272062Z",
     "shell.execute_reply": "2024-02-14T12:57:36.271037Z"
    },
    "papermill": {
     "duration": 0.070682,
     "end_time": "2024-02-14T12:57:36.274457",
     "exception": false,
     "start_time": "2024-02-14T12:57:36.203775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 5) (179, 5) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "x_tr, x_va, y_tr, y_va = train_test_split(x_train, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_tr.shape, x_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e26a67",
   "metadata": {
    "papermill": {
     "duration": 0.049009,
     "end_time": "2024-02-14T12:57:36.372892",
     "exception": false,
     "start_time": "2024-02-14T12:57:36.323883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-20: モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab9f12a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:36.473777Z",
     "iopub.status.busy": "2024-02-14T12:57:36.473094Z",
     "iopub.status.idle": "2024-02-14T12:57:36.757055Z",
     "shell.execute_reply": "2024-02-14T12:57:36.755750Z"
    },
    "papermill": {
     "duration": 0.349435,
     "end_time": "2024-02-14T12:57:36.771736",
     "exception": false,
     "start_time": "2024-02-14T12:57:36.422301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                60        \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 10)                40        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 10)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 10)                40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 5)                 20        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 5)                 0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 331 (1.29 KB)\n",
      "Trainable params: 281 (1.10 KB)\n",
      "Non-trainable params: 50 (200.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    input_num = Input(shape=(5,))\n",
    "    x_num = Dense(10, activation=\"relu\")(input_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.3)(x_num)\n",
    "    x_num = Dense(10, activation=\"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.2)(x_num)\n",
    "    x_num = Dense(5, activation=\"relu\")(x_num)\n",
    "    x_num = BatchNormalization()(x_num)\n",
    "    x_num = Dropout(0.1)(x_num)\n",
    "    out = Dense(1, activation=\"sigmoid\")(x_num)\n",
    "\n",
    "    model = Model(inputs=input_num,\n",
    "                  outputs=out,\n",
    "                 )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"binary_crossentropy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23151e7f",
   "metadata": {
    "papermill": {
     "duration": 0.053202,
     "end_time": "2024-02-14T12:57:36.876889",
     "exception": false,
     "start_time": "2024-02-14T12:57:36.823687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-21: モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bbe4d81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:36.984606Z",
     "iopub.status.busy": "2024-02-14T12:57:36.984180Z",
     "iopub.status.idle": "2024-02-14T12:57:52.564924Z",
     "shell.execute_reply": "2024-02-14T12:57:52.563934Z"
    },
    "papermill": {
     "duration": 15.637967,
     "end_time": "2024-02-14T12:57:52.567213",
     "exception": false,
     "start_time": "2024-02-14T12:57:36.929246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "76/89 [========================>.....] - ETA: 0s - loss: 0.7278 - binary_crossentropy: 0.7278\n",
      "Epoch 1: val_loss improved from inf to 0.68176, saving model to model_keras.h5\n",
      "89/89 [==============================] - 3s 7ms/step - loss: 0.7268 - binary_crossentropy: 0.7268 - val_loss: 0.6818 - val_binary_crossentropy: 0.6818 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "72/89 [=======================>......] - ETA: 0s - loss: 0.6810 - binary_crossentropy: 0.6810\n",
      "Epoch 2: val_loss improved from 0.68176 to 0.66805, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6753 - binary_crossentropy: 0.6753 - val_loss: 0.6681 - val_binary_crossentropy: 0.6681 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "74/89 [=======================>......] - ETA: 0s - loss: 0.6898 - binary_crossentropy: 0.6898\n",
      "Epoch 3: val_loss improved from 0.66805 to 0.65480, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6801 - binary_crossentropy: 0.6801 - val_loss: 0.6548 - val_binary_crossentropy: 0.6548 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "69/89 [======================>.......] - ETA: 0s - loss: 0.6528 - binary_crossentropy: 0.6528\n",
      "Epoch 4: val_loss improved from 0.65480 to 0.63951, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6526 - binary_crossentropy: 0.6526 - val_loss: 0.6395 - val_binary_crossentropy: 0.6395 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "77/89 [========================>.....] - ETA: 0s - loss: 0.6588 - binary_crossentropy: 0.6588\n",
      "Epoch 5: val_loss improved from 0.63951 to 0.62343, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6539 - binary_crossentropy: 0.6539 - val_loss: 0.6234 - val_binary_crossentropy: 0.6234 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.6588 - binary_crossentropy: 0.6588\n",
      "Epoch 6: val_loss improved from 0.62343 to 0.61811, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6614 - binary_crossentropy: 0.6614 - val_loss: 0.6181 - val_binary_crossentropy: 0.6181 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "84/89 [===========================>..] - ETA: 0s - loss: 0.6591 - binary_crossentropy: 0.6591\n",
      "Epoch 7: val_loss improved from 0.61811 to 0.61267, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6605 - binary_crossentropy: 0.6605 - val_loss: 0.6127 - val_binary_crossentropy: 0.6127 - lr: 0.0010\n",
      "Epoch 8/10000\n",
      "77/89 [========================>.....] - ETA: 0s - loss: 0.6519 - binary_crossentropy: 0.6519\n",
      "Epoch 8: val_loss did not improve from 0.61267\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6448 - binary_crossentropy: 0.6448 - val_loss: 0.6185 - val_binary_crossentropy: 0.6185 - lr: 0.0010\n",
      "Epoch 9/10000\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.6467 - binary_crossentropy: 0.6467\n",
      "Epoch 9: val_loss improved from 0.61267 to 0.61192, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6473 - binary_crossentropy: 0.6473 - val_loss: 0.6119 - val_binary_crossentropy: 0.6119 - lr: 0.0010\n",
      "Epoch 10/10000\n",
      "78/89 [=========================>....] - ETA: 0s - loss: 0.6284 - binary_crossentropy: 0.6284\n",
      "Epoch 10: val_loss improved from 0.61192 to 0.60599, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6262 - binary_crossentropy: 0.6262 - val_loss: 0.6060 - val_binary_crossentropy: 0.6060 - lr: 0.0010\n",
      "Epoch 11/10000\n",
      "78/89 [=========================>....] - ETA: 0s - loss: 0.6471 - binary_crossentropy: 0.6471\n",
      "Epoch 11: val_loss improved from 0.60599 to 0.60516, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6488 - binary_crossentropy: 0.6488 - val_loss: 0.6052 - val_binary_crossentropy: 0.6052 - lr: 0.0010\n",
      "Epoch 12/10000\n",
      "80/89 [=========================>....] - ETA: 0s - loss: 0.6392 - binary_crossentropy: 0.6392\n",
      "Epoch 12: val_loss did not improve from 0.60516\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6377 - binary_crossentropy: 0.6377 - val_loss: 0.6056 - val_binary_crossentropy: 0.6056 - lr: 0.0010\n",
      "Epoch 13/10000\n",
      "73/89 [=======================>......] - ETA: 0s - loss: 0.6475 - binary_crossentropy: 0.6475\n",
      "Epoch 13: val_loss improved from 0.60516 to 0.60494, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6441 - binary_crossentropy: 0.6441 - val_loss: 0.6049 - val_binary_crossentropy: 0.6049 - lr: 0.0010\n",
      "Epoch 14/10000\n",
      "74/89 [=======================>......] - ETA: 0s - loss: 0.6242 - binary_crossentropy: 0.6242\n",
      "Epoch 14: val_loss improved from 0.60494 to 0.59610, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6208 - binary_crossentropy: 0.6208 - val_loss: 0.5961 - val_binary_crossentropy: 0.5961 - lr: 0.0010\n",
      "Epoch 15/10000\n",
      "72/89 [=======================>......] - ETA: 0s - loss: 0.6151 - binary_crossentropy: 0.6151\n",
      "Epoch 15: val_loss improved from 0.59610 to 0.59132, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_crossentropy: 0.6176 - val_loss: 0.5913 - val_binary_crossentropy: 0.5913 - lr: 0.0010\n",
      "Epoch 16/10000\n",
      "71/89 [======================>.......] - ETA: 0s - loss: 0.6043 - binary_crossentropy: 0.6043\n",
      "Epoch 16: val_loss improved from 0.59132 to 0.58463, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6098 - binary_crossentropy: 0.6098 - val_loss: 0.5846 - val_binary_crossentropy: 0.5846 - lr: 0.0010\n",
      "Epoch 17/10000\n",
      "83/89 [==========================>...] - ETA: 0s - loss: 0.6203 - binary_crossentropy: 0.6203\n",
      "Epoch 17: val_loss did not improve from 0.58463\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6251 - binary_crossentropy: 0.6251 - val_loss: 0.5897 - val_binary_crossentropy: 0.5897 - lr: 0.0010\n",
      "Epoch 18/10000\n",
      "83/89 [==========================>...] - ETA: 0s - loss: 0.6176 - binary_crossentropy: 0.6176\n",
      "Epoch 18: val_loss did not improve from 0.58463\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6181 - binary_crossentropy: 0.6181 - val_loss: 0.5878 - val_binary_crossentropy: 0.5878 - lr: 0.0010\n",
      "Epoch 19/10000\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.6066 - binary_crossentropy: 0.6066\n",
      "Epoch 19: val_loss improved from 0.58463 to 0.58410, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6072 - binary_crossentropy: 0.6072 - val_loss: 0.5841 - val_binary_crossentropy: 0.5841 - lr: 0.0010\n",
      "Epoch 20/10000\n",
      "81/89 [==========================>...] - ETA: 0s - loss: 0.6239 - binary_crossentropy: 0.6239\n",
      "Epoch 20: val_loss did not improve from 0.58410\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6232 - binary_crossentropy: 0.6232 - val_loss: 0.5876 - val_binary_crossentropy: 0.5876 - lr: 0.0010\n",
      "Epoch 21/10000\n",
      "80/89 [=========================>....] - ETA: 0s - loss: 0.6328 - binary_crossentropy: 0.6328\n",
      "Epoch 21: val_loss did not improve from 0.58410\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6317 - binary_crossentropy: 0.6317 - val_loss: 0.5848 - val_binary_crossentropy: 0.5848 - lr: 0.0010\n",
      "Epoch 22/10000\n",
      "84/89 [===========================>..] - ETA: 0s - loss: 0.6281 - binary_crossentropy: 0.6281\n",
      "Epoch 22: val_loss improved from 0.58410 to 0.57950, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6258 - binary_crossentropy: 0.6258 - val_loss: 0.5795 - val_binary_crossentropy: 0.5795 - lr: 0.0010\n",
      "Epoch 23/10000\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.6186 - binary_crossentropy: 0.6186\n",
      "Epoch 23: val_loss improved from 0.57950 to 0.57822, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6175 - binary_crossentropy: 0.6175 - val_loss: 0.5782 - val_binary_crossentropy: 0.5782 - lr: 0.0010\n",
      "Epoch 24/10000\n",
      "73/89 [=======================>......] - ETA: 0s - loss: 0.6259 - binary_crossentropy: 0.6259\n",
      "Epoch 24: val_loss did not improve from 0.57822\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6242 - binary_crossentropy: 0.6242 - val_loss: 0.5790 - val_binary_crossentropy: 0.5790 - lr: 0.0010\n",
      "Epoch 25/10000\n",
      "71/89 [======================>.......] - ETA: 0s - loss: 0.6159 - binary_crossentropy: 0.6159\n",
      "Epoch 25: val_loss improved from 0.57822 to 0.57419, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6176 - binary_crossentropy: 0.6176 - val_loss: 0.5742 - val_binary_crossentropy: 0.5742 - lr: 0.0010\n",
      "Epoch 26/10000\n",
      "76/89 [========================>.....] - ETA: 0s - loss: 0.6166 - binary_crossentropy: 0.6166\n",
      "Epoch 26: val_loss did not improve from 0.57419\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6091 - binary_crossentropy: 0.6091 - val_loss: 0.5764 - val_binary_crossentropy: 0.5764 - lr: 0.0010\n",
      "Epoch 27/10000\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.6184 - binary_crossentropy: 0.6184\n",
      "Epoch 27: val_loss did not improve from 0.57419\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6205 - binary_crossentropy: 0.6205 - val_loss: 0.5787 - val_binary_crossentropy: 0.5787 - lr: 0.0010\n",
      "Epoch 28/10000\n",
      "86/89 [===========================>..] - ETA: 0s - loss: 0.6221 - binary_crossentropy: 0.6221\n",
      "Epoch 28: val_loss did not improve from 0.57419\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6258 - binary_crossentropy: 0.6258 - val_loss: 0.5802 - val_binary_crossentropy: 0.5802 - lr: 0.0010\n",
      "Epoch 29/10000\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.6016 - binary_crossentropy: 0.6016\n",
      "Epoch 29: val_loss did not improve from 0.57419\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6021 - binary_crossentropy: 0.6021 - val_loss: 0.5792 - val_binary_crossentropy: 0.5792 - lr: 0.0010\n",
      "Epoch 30/10000\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.6014 - binary_crossentropy: 0.6014\n",
      "Epoch 30: val_loss improved from 0.57419 to 0.57143, saving model to model_keras.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6019 - binary_crossentropy: 0.6019 - val_loss: 0.5714 - val_binary_crossentropy: 0.5714 - lr: 0.0010\n",
      "Epoch 31/10000\n",
      "79/89 [=========================>....] - ETA: 0s - loss: 0.6254 - binary_crossentropy: 0.6254\n",
      "Epoch 31: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6238 - binary_crossentropy: 0.6238 - val_loss: 0.5714 - val_binary_crossentropy: 0.5714 - lr: 0.0010\n",
      "Epoch 32/10000\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.6240 - binary_crossentropy: 0.6240\n",
      "Epoch 32: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6239 - binary_crossentropy: 0.6239 - val_loss: 0.5777 - val_binary_crossentropy: 0.5777 - lr: 0.0010\n",
      "Epoch 33/10000\n",
      "79/89 [=========================>....] - ETA: 0s - loss: 0.6284 - binary_crossentropy: 0.6284\n",
      "Epoch 33: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6229 - binary_crossentropy: 0.6229 - val_loss: 0.5778 - val_binary_crossentropy: 0.5778 - lr: 0.0010\n",
      "Epoch 34/10000\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.6197 - binary_crossentropy: 0.6197\n",
      "Epoch 34: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6194 - binary_crossentropy: 0.6194 - val_loss: 0.5802 - val_binary_crossentropy: 0.5802 - lr: 0.0010\n",
      "Epoch 35/10000\n",
      "73/89 [=======================>......] - ETA: 0s - loss: 0.6208 - binary_crossentropy: 0.6208\n",
      "Epoch 35: val_loss did not improve from 0.57143\n",
      "\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6172 - binary_crossentropy: 0.6172 - val_loss: 0.5744 - val_binary_crossentropy: 0.5744 - lr: 0.0010\n",
      "Epoch 36/10000\n",
      "71/89 [======================>.......] - ETA: 0s - loss: 0.6089 - binary_crossentropy: 0.6089\n",
      "Epoch 36: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6155 - binary_crossentropy: 0.6155 - val_loss: 0.5749 - val_binary_crossentropy: 0.5749 - lr: 1.0000e-04\n",
      "Epoch 37/10000\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.5999 - binary_crossentropy: 0.5999\n",
      "Epoch 37: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6052 - binary_crossentropy: 0.6052 - val_loss: 0.5739 - val_binary_crossentropy: 0.5739 - lr: 1.0000e-04\n",
      "Epoch 38/10000\n",
      "85/89 [===========================>..] - ETA: 0s - loss: 0.6091 - binary_crossentropy: 0.6091\n",
      "Epoch 38: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6059 - binary_crossentropy: 0.6059 - val_loss: 0.5752 - val_binary_crossentropy: 0.5752 - lr: 1.0000e-04\n",
      "Epoch 39/10000\n",
      "83/89 [==========================>...] - ETA: 0s - loss: 0.6211 - binary_crossentropy: 0.6211\n",
      "Epoch 39: val_loss did not improve from 0.57143\n",
      "89/89 [==============================] - 0s 3ms/step - loss: 0.6202 - binary_crossentropy: 0.6202 - val_loss: 0.5750 - val_binary_crossentropy: 0.5750 - lr: 1.0000e-04\n",
      "Epoch 40/10000\n",
      "88/89 [============================>.] - ETA: 0s - loss: 0.6186 - binary_crossentropy: 0.6186\n",
      "Epoch 40: val_loss did not improve from 0.57143\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6168 - binary_crossentropy: 0.6168 - val_loss: 0.5737 - val_binary_crossentropy: 0.5737 - lr: 1.0000e-04\n",
      "Epoch 40: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d520da7d0f0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(seed=123)\n",
    "model = create_model()\n",
    "model.fit(x=x_tr,\n",
    "          y=y_tr,\n",
    "          validation_data=(x_va, y_va),\n",
    "          batch_size=8,\n",
    "          epochs=10000,\n",
    "          callbacks=[\n",
    "              ModelCheckpoint(filepath=\"model_keras.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n",
    "              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n",
    "              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n",
    "          ],\n",
    "          verbose=1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a1c844",
   "metadata": {
    "papermill": {
     "duration": 0.082813,
     "end_time": "2024-02-14T12:57:52.732218",
     "exception": false,
     "start_time": "2024-02-14T12:57:52.649405",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-22: モデルの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d917487d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:57:52.899605Z",
     "iopub.status.busy": "2024-02-14T12:57:52.899152Z",
     "iopub.status.idle": "2024-02-14T12:58:00.188569Z",
     "shell.execute_reply": "2024-02-14T12:58:00.187379Z"
    },
    "papermill": {
     "duration": 7.376076,
     "end_time": "2024-02-14T12:58:00.190917",
     "exception": false,
     "start_time": "2024-02-14T12:57:52.814841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 1ms/step\n",
      "accuracy: 0.7095\n"
     ]
    }
   ],
   "source": [
    "y_va_pred = model.predict(x_va, batch_size=8, verbose=1)\n",
    "print(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b3c37d",
   "metadata": {
    "papermill": {
     "duration": 0.082158,
     "end_time": "2024-02-14T12:58:00.354597",
     "exception": false,
     "start_time": "2024-02-14T12:58:00.272439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ニューラルネットワークの適用例：②埋め込み層ありのネットワークモデル\n",
    "#### スクリプト6-23: ファイルの読み込みとデータセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc87d1b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:00.520820Z",
     "iopub.status.busy": "2024-02-14T12:58:00.520418Z",
     "iopub.status.idle": "2024-02-14T12:58:00.534771Z",
     "shell.execute_reply": "2024-02-14T12:58:00.533717Z"
    },
    "papermill": {
     "duration": 0.101224,
     "end_time": "2024-02-14T12:58:00.537528",
     "exception": false,
     "start_time": "2024-02-14T12:58:00.436304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ファイル読み込み\n",
    "df_train = pd.read_csv(\"../input/titanic/train.csv\")\n",
    "\n",
    "# データセット作成\n",
    "x_train = df_train[[\"Pclass\", \"Age\", \"Cabin\"]]\n",
    "y_train = df_train[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3382af26",
   "metadata": {
    "papermill": {
     "duration": 0.081107,
     "end_time": "2024-02-14T12:58:00.700104",
     "exception": false,
     "start_time": "2024-02-14T12:58:00.618997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-24: 数値データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d125c5e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:00.865210Z",
     "iopub.status.busy": "2024-02-14T12:58:00.864811Z",
     "iopub.status.idle": "2024-02-14T12:58:00.876760Z",
     "shell.execute_reply": "2024-02-14T12:58:00.875649Z"
    },
    "papermill": {
     "duration": 0.097187,
     "end_time": "2024-02-14T12:58:00.879279",
     "exception": false,
     "start_time": "2024-02-14T12:58:00.782092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Age\"] = x_train[\"Age\"].fillna(x_train[\"Age\"].mean())\n",
    "\n",
    "# 正規化\n",
    "for col in [\"Pclass\", \"Age\"]:\n",
    "    value_min = x_train[col].min()\n",
    "    value_max = x_train[col].max()\n",
    "    x_train[col] = (x_train[col] - value_min) / (value_max - value_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8a1857",
   "metadata": {
    "papermill": {
     "duration": 0.08279,
     "end_time": "2024-02-14T12:58:01.047837",
     "exception": false,
     "start_time": "2024-02-14T12:58:00.965047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-25: カテゴリ変数の前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc531083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:01.218134Z",
     "iopub.status.busy": "2024-02-14T12:58:01.217674Z",
     "iopub.status.idle": "2024-02-14T12:58:01.229741Z",
     "shell.execute_reply": "2024-02-14T12:58:01.228385Z"
    },
    "papermill": {
     "duration": 0.100191,
     "end_time": "2024-02-14T12:58:01.232079",
     "exception": false,
     "start_time": "2024-02-14T12:58:01.131888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A10' 'A14' 'A16' 'A19' 'A20' 'A23' 'A24' 'A26' 'A31' 'A32' 'A34' 'A36'\n",
      " 'A5' 'A6' 'A7' 'B101' 'B102' 'B18' 'B19' 'B20' 'B22' 'B28' 'B3' 'B30'\n",
      " 'B35' 'B37' 'B38' 'B39' 'B4' 'B41' 'B42' 'B49' 'B5' 'B50' 'B51 B53 B55'\n",
      " 'B57 B59 B63 B66' 'B58 B60' 'B69' 'B71' 'B73' 'B77' 'B78' 'B79' 'B80'\n",
      " 'B82 B84' 'B86' 'B94' 'B96 B98' 'C101' 'C103' 'C104' 'C106' 'C110' 'C111'\n",
      " 'C118' 'C123' 'C124' 'C125' 'C126' 'C128' 'C148' 'C2' 'C22 C26'\n",
      " 'C23 C25 C27' 'C30' 'C32' 'C45' 'C46' 'C47' 'C49' 'C50' 'C52' 'C54'\n",
      " 'C62 C64' 'C65' 'C68' 'C7' 'C70' 'C78' 'C82' 'C83' 'C85' 'C86' 'C87'\n",
      " 'C90' 'C91' 'C92' 'C93' 'C95' 'C99' 'D' 'D10 D12' 'D11' 'D15' 'D17' 'D19'\n",
      " 'D20' 'D21' 'D26' 'D28' 'D30' 'D33' 'D35' 'D36' 'D37' 'D45' 'D46' 'D47'\n",
      " 'D48' 'D49' 'D50' 'D56' 'D6' 'D7' 'D9' 'E10' 'E101' 'E12' 'E121' 'E17'\n",
      " 'E24' 'E25' 'E31' 'E33' 'E34' 'E36' 'E38' 'E40' 'E44' 'E46' 'E49' 'E50'\n",
      " 'E58' 'E63' 'E67' 'E68' 'E77' 'E8' 'F E69' 'F G63' 'F G73' 'F2' 'F33'\n",
      " 'F38' 'F4' 'G6' 'None' 'T']\n",
      "count: 148\n"
     ]
    }
   ],
   "source": [
    "# 欠損値補間\n",
    "x_train[\"Cabin\"] = x_train[\"Cabin\"].fillna(\"None\")\n",
    "\n",
    "# label-encoding\n",
    "le = LabelEncoder()\n",
    "le.fit(x_train[[\"Cabin\"]])\n",
    "x_train[\"Cabin\"] = le.transform(x_train[\"Cabin\"])\n",
    "\n",
    "print(le.classes_)\n",
    "print(\"count:\", len(le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7f092",
   "metadata": {
    "papermill": {
     "duration": 0.084854,
     "end_time": "2024-02-14T12:58:01.401933",
     "exception": false,
     "start_time": "2024-02-14T12:58:01.317079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-26: 学習データと検証データの分離"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af2acca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:01.573427Z",
     "iopub.status.busy": "2024-02-14T12:58:01.572932Z",
     "iopub.status.idle": "2024-02-14T12:58:01.593870Z",
     "shell.execute_reply": "2024-02-14T12:58:01.592119Z"
    },
    "papermill": {
     "duration": 0.10923,
     "end_time": "2024-02-14T12:58:01.597279",
     "exception": false,
     "start_time": "2024-02-14T12:58:01.488049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 2) (179, 2) (712, 1) (179, 1) (712, 1) (179, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_num, x_train_cat = x_train[[\"Pclass\", \"Age\"]], x_train[[\"Cabin\"]]\n",
    "\n",
    "x_num_tr, x_num_va, x_cat_tr, x_cat_va, y_tr, y_va = \\\n",
    "   train_test_split(x_train_num, x_train_cat, y_train, test_size=0.2, stratify=y_train, random_state=123)\n",
    "print(x_num_tr.shape, x_num_va.shape, x_cat_tr.shape, x_cat_va.shape, y_tr.shape, y_va.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d79888",
   "metadata": {
    "papermill": {
     "duration": 0.083558,
     "end_time": "2024-02-14T12:58:01.765647",
     "exception": false,
     "start_time": "2024-02-14T12:58:01.682089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-27: モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19423a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:01.934744Z",
     "iopub.status.busy": "2024-02-14T12:58:01.934230Z",
     "iopub.status.idle": "2024-02-14T12:58:02.222879Z",
     "shell.execute_reply": "2024-02-14T12:58:02.221329Z"
    },
    "papermill": {
     "duration": 0.376199,
     "end_time": "2024-02-14T12:58:02.225298",
     "exception": false,
     "start_time": "2024-02-14T12:58:01.849099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 10)                   30        ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (None,)                      0         ['input_4[0][0]']             \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 10)                   40        ['dense_8[0][0]']             \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 74)                   10952     ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 10)                   0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 74)                   0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 10)                   110       ['dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 74)                   0         ['dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 84)                   0         ['dense_9[0][0]',             \n",
      "                                                                     'flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 50)                   4250      ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 50)                   200       ['dense_10[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, 50)                   0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 20)                   1020      ['dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 20)                   80        ['dense_11[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, 20)                   0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 1)                    21        ['dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16703 (65.25 KB)\n",
      "Trainable params: 16543 (64.62 KB)\n",
      "Non-trainable params: 160 (640.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model_embedding():\n",
    "    ################# num\n",
    "    input_num = Input(shape=(2,))\n",
    "    layer_num = Dense(10, activation=\"relu\")(input_num)\n",
    "    layer_num = BatchNormalization()(layer_num)\n",
    "    layer_num = Dropout(0.2)(layer_num)\n",
    "    layer_num = Dense(10, activation=\"relu\")(layer_num)\n",
    "\n",
    "    ################# cat\n",
    "    input_cat = Input(shape=(1,))\n",
    "    layer_cat = input_cat[:, 0]\n",
    "    layer_cat = Embedding(input_dim=148, output_dim=74)(layer_cat)\n",
    "    layer_cat = Dropout(0.2)(layer_cat)\n",
    "    layer_cat = Flatten()(layer_cat)\n",
    "\n",
    "    ################# concat\n",
    "    hidden_layer = Concatenate()([layer_num, layer_cat])\n",
    "    hidden_layer = Dense(50, activation=\"relu\")(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(0.1)(hidden_layer)\n",
    "    hidden_layer = Dense(20, activation=\"relu\")(hidden_layer)\n",
    "    hidden_layer = BatchNormalization()(hidden_layer)\n",
    "    hidden_layer = Dropout(0.1)(hidden_layer)\n",
    "    output_layer = Dense(1, activation=\"sigmoid\")(hidden_layer)\n",
    "\n",
    "    model = Model(inputs=[input_num, input_cat],\n",
    "                  outputs=output_layer,\n",
    "                 )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"Adam\",\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"binary_crossentropy\"],\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model_embedding()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60cb253",
   "metadata": {
    "papermill": {
     "duration": 0.093083,
     "end_time": "2024-02-14T12:58:02.410109",
     "exception": false,
     "start_time": "2024-02-14T12:58:02.317026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-28: モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dd1c45d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:02.590159Z",
     "iopub.status.busy": "2024-02-14T12:58:02.589495Z",
     "iopub.status.idle": "2024-02-14T12:58:10.714200Z",
     "shell.execute_reply": "2024-02-14T12:58:10.713154Z"
    },
    "papermill": {
     "duration": 8.217441,
     "end_time": "2024-02-14T12:58:10.716561",
     "exception": false,
     "start_time": "2024-02-14T12:58:02.499120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "73/89 [=======================>......] - ETA: 0s - loss: 0.7891 - binary_crossentropy: 0.7891\n",
      "Epoch 1: val_loss improved from inf to 0.65861, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 3s 8ms/step - loss: 0.7850 - binary_crossentropy: 0.7850 - val_loss: 0.6586 - val_binary_crossentropy: 0.6586 - lr: 0.0010\n",
      "Epoch 2/10000\n",
      "84/89 [===========================>..] - ETA: 0s - loss: 0.6657 - binary_crossentropy: 0.6657\n",
      "Epoch 2: val_loss improved from 0.65861 to 0.65290, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6631 - binary_crossentropy: 0.6631 - val_loss: 0.6529 - val_binary_crossentropy: 0.6529 - lr: 0.0010\n",
      "Epoch 3/10000\n",
      "82/89 [==========================>...] - ETA: 0s - loss: 0.6518 - binary_crossentropy: 0.6518\n",
      "Epoch 3: val_loss improved from 0.65290 to 0.64176, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6440 - binary_crossentropy: 0.6440 - val_loss: 0.6418 - val_binary_crossentropy: 0.6418 - lr: 0.0010\n",
      "Epoch 4/10000\n",
      "80/89 [=========================>....] - ETA: 0s - loss: 0.6345 - binary_crossentropy: 0.6345\n",
      "Epoch 4: val_loss improved from 0.64176 to 0.61593, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6320 - binary_crossentropy: 0.6320 - val_loss: 0.6159 - val_binary_crossentropy: 0.6159 - lr: 0.0010\n",
      "Epoch 5/10000\n",
      "82/89 [==========================>...] - ETA: 0s - loss: 0.6088 - binary_crossentropy: 0.6088\n",
      "Epoch 5: val_loss did not improve from 0.61593\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.6064 - binary_crossentropy: 0.6064 - val_loss: 0.6177 - val_binary_crossentropy: 0.6177 - lr: 0.0010\n",
      "Epoch 6/10000\n",
      "79/89 [=========================>....] - ETA: 0s - loss: 0.5987 - binary_crossentropy: 0.5987\n",
      "Epoch 6: val_loss improved from 0.61593 to 0.58922, saving model to model_keras_embedding.h5\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5930 - binary_crossentropy: 0.5930 - val_loss: 0.5892 - val_binary_crossentropy: 0.5892 - lr: 0.0010\n",
      "Epoch 7/10000\n",
      "77/89 [========================>.....] - ETA: 0s - loss: 0.5790 - binary_crossentropy: 0.5790\n",
      "Epoch 7: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5855 - binary_crossentropy: 0.5855 - val_loss: 0.6132 - val_binary_crossentropy: 0.6132 - lr: 0.0010\n",
      "Epoch 8/10000\n",
      "80/89 [=========================>....] - ETA: 0s - loss: 0.5519 - binary_crossentropy: 0.5519\n",
      "Epoch 8: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5578 - binary_crossentropy: 0.5578 - val_loss: 0.6386 - val_binary_crossentropy: 0.6386 - lr: 0.0010\n",
      "Epoch 9/10000\n",
      "78/89 [=========================>....] - ETA: 0s - loss: 0.5502 - binary_crossentropy: 0.5502\n",
      "Epoch 9: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5514 - binary_crossentropy: 0.5514 - val_loss: 0.6378 - val_binary_crossentropy: 0.6378 - lr: 0.0010\n",
      "Epoch 10/10000\n",
      "80/89 [=========================>....] - ETA: 0s - loss: 0.5529 - binary_crossentropy: 0.5529\n",
      "Epoch 10: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5538 - binary_crossentropy: 0.5538 - val_loss: 0.6402 - val_binary_crossentropy: 0.6402 - lr: 0.0010\n",
      "Epoch 11/10000\n",
      "78/89 [=========================>....] - ETA: 0s - loss: 0.5511 - binary_crossentropy: 0.5511\n",
      "Epoch 11: val_loss did not improve from 0.58922\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5571 - binary_crossentropy: 0.5571 - val_loss: 0.6475 - val_binary_crossentropy: 0.6475 - lr: 0.0010\n",
      "Epoch 12/10000\n",
      "79/89 [=========================>....] - ETA: 0s - loss: 0.5364 - binary_crossentropy: 0.5364\n",
      "Epoch 12: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5269 - binary_crossentropy: 0.5269 - val_loss: 0.6454 - val_binary_crossentropy: 0.6454 - lr: 1.0000e-04\n",
      "Epoch 13/10000\n",
      "82/89 [==========================>...] - ETA: 0s - loss: 0.5486 - binary_crossentropy: 0.5486\n",
      "Epoch 13: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5563 - binary_crossentropy: 0.5563 - val_loss: 0.6468 - val_binary_crossentropy: 0.6468 - lr: 1.0000e-04\n",
      "Epoch 14/10000\n",
      "82/89 [==========================>...] - ETA: 0s - loss: 0.5230 - binary_crossentropy: 0.5230\n",
      "Epoch 14: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5262 - binary_crossentropy: 0.5262 - val_loss: 0.6473 - val_binary_crossentropy: 0.6473 - lr: 1.0000e-04\n",
      "Epoch 15/10000\n",
      "82/89 [==========================>...] - ETA: 0s - loss: 0.5360 - binary_crossentropy: 0.5360\n",
      "Epoch 15: val_loss did not improve from 0.58922\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5330 - binary_crossentropy: 0.5330 - val_loss: 0.6474 - val_binary_crossentropy: 0.6474 - lr: 1.0000e-04\n",
      "Epoch 16/10000\n",
      "87/89 [============================>.] - ETA: 0s - loss: 0.5471 - binary_crossentropy: 0.5471\n",
      "Epoch 16: val_loss did not improve from 0.58922\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "89/89 [==============================] - 0s 4ms/step - loss: 0.5497 - binary_crossentropy: 0.5497 - val_loss: 0.6494 - val_binary_crossentropy: 0.6494 - lr: 1.0000e-04\n",
      "Epoch 16: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7d5206fb28f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(seed=123)\n",
    "model = create_model_embedding()\n",
    "model.fit(x=[x_num_tr, x_cat_tr],\n",
    "          y=y_tr,\n",
    "          validation_data=([x_num_va, x_cat_va], y_va),\n",
    "          batch_size=8,\n",
    "          epochs=10000,\n",
    "          callbacks=[\n",
    "              ModelCheckpoint(filepath=\"model_keras_embedding.h5\", monitor=\"val_loss\", mode=\"min\", verbose=1, save_best_only=True, save_weights_only=True),\n",
    "              EarlyStopping(monitor=\"val_loss\", mode=\"min\", min_delta=0, patience=10, verbose=1, restore_best_weights=True),\n",
    "              ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\", factor=0.1, patience=5, verbose=1),\n",
    "          ],\n",
    "          verbose=1,\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6971db19",
   "metadata": {
    "papermill": {
     "duration": 0.099847,
     "end_time": "2024-02-14T12:58:10.916141",
     "exception": false,
     "start_time": "2024-02-14T12:58:10.816294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-29: モデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd903232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:11.117193Z",
     "iopub.status.busy": "2024-02-14T12:58:11.116774Z",
     "iopub.status.idle": "2024-02-14T12:58:15.572706Z",
     "shell.execute_reply": "2024-02-14T12:58:15.571781Z"
    },
    "papermill": {
     "duration": 4.558418,
     "end_time": "2024-02-14T12:58:15.575010",
     "exception": false,
     "start_time": "2024-02-14T12:58:11.016592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 2ms/step\n",
      "accuracy: 0.7151\n"
     ]
    }
   ],
   "source": [
    "y_va_pred = model.predict([x_num_va, x_cat_va], batch_size=8, verbose=1)\n",
    "print(\"accuracy: {:.4f}\".format(accuracy_score(y_va, np.where(y_va_pred>=0.5,1,0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ed3404",
   "metadata": {
    "papermill": {
     "duration": 0.100622,
     "end_time": "2024-02-14T12:58:15.776648",
     "exception": false,
     "start_time": "2024-02-14T12:58:15.676026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6.3 アンサンブル\n",
    "## 6.3.1 単純平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b142677",
   "metadata": {
    "papermill": {
     "duration": 0.101841,
     "end_time": "2024-02-14T12:58:15.978802",
     "exception": false,
     "start_time": "2024-02-14T12:58:15.876961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-30: 3モデルの予測値を持つデータフレームを乱数で作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eaee0394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:16.187096Z",
     "iopub.status.busy": "2024-02-14T12:58:16.186330Z",
     "iopub.status.idle": "2024-02-14T12:58:16.220230Z",
     "shell.execute_reply": "2024-02-14T12:58:16.218954Z"
    },
    "papermill": {
     "duration": 0.139793,
     "end_time": "2024-02-14T12:58:16.222630",
     "exception": false,
     "start_time": "2024-02-14T12:58:16.082837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3\n",
       "0     1  0.683821  0.874443  0.859939\n",
       "1     0  0.540691  0.113419  0.197144\n",
       "2     0  0.310541  0.334798  0.599304\n",
       "3     0  0.043486  0.170622  0.378528\n",
       "4     0  0.550847  0.354703  0.598860"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "df = pd.DataFrame({\n",
    "    \"true\": [0]*700 + [1]*300,\n",
    "    \"pred1\":np.arange(1000) + np.random.rand(1000)*1200,\n",
    "    \"pred2\":np.arange(1000) + np.random.rand(1000)*1000,\n",
    "    \"pred3\":np.arange(1000) + np.random.rand(1000)*800,\n",
    "})\n",
    "df[\"pred1\"] = np.clip(df[\"pred1\"]/df[\"pred1\"].max(), 0, 1)\n",
    "df[\"pred2\"] = np.clip(df[\"pred2\"]/df[\"pred2\"].max(), 0, 1)\n",
    "df[\"pred3\"] = np.clip(df[\"pred3\"]/df[\"pred3\"].max(), 0, 1)\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.8, stratify=df[\"true\"], random_state=123)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798633bc",
   "metadata": {
    "papermill": {
     "duration": 0.100758,
     "end_time": "2024-02-14T12:58:16.424427",
     "exception": false,
     "start_time": "2024-02-14T12:58:16.323669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-31: 単純平均によるアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33cf2f43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:16.629483Z",
     "iopub.status.busy": "2024-02-14T12:58:16.628681Z",
     "iopub.status.idle": "2024-02-14T12:58:16.643896Z",
     "shell.execute_reply": "2024-02-14T12:58:16.642786Z"
    },
    "papermill": {
     "duration": 0.121099,
     "end_time": "2024-02-14T12:58:16.646555",
     "exception": false,
     "start_time": "2024-02-14T12:58:16.525456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.806068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.283752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.414881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.197545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.501470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble1\n",
       "0     1  0.683821  0.874443  0.859939        0.806068\n",
       "1     0  0.540691  0.113419  0.197144        0.283752\n",
       "2     0  0.310541  0.334798  0.599304        0.414881\n",
       "3     0  0.043486  0.170622  0.378528        0.197545\n",
       "4     0  0.550847  0.354703  0.598860        0.501470"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"pred_ensemble1\"] = (df_train[\"pred1\"] + df_train[\"pred2\"] + df_train[\"pred3\"]) / 3\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1f62f",
   "metadata": {
    "papermill": {
     "duration": 0.100182,
     "end_time": "2024-02-14T12:58:16.849762",
     "exception": false,
     "start_time": "2024-02-14T12:58:16.749580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-32: アンサンブル用の精度評価関数と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a3f2e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:17.063569Z",
     "iopub.status.busy": "2024-02-14T12:58:17.062662Z",
     "iopub.status.idle": "2024-02-14T12:58:17.080013Z",
     "shell.execute_reply": "2024-02-14T12:58:17.078659Z"
    },
    "papermill": {
     "duration": 0.129429,
     "end_time": "2024-02-14T12:58:17.083770",
     "exception": false,
     "start_time": "2024-02-14T12:58:16.954341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9585\n"
     ]
    }
   ],
   "source": [
    "def evaluate_ensemble(input_df, col_pred):\n",
    "    print(\"[auc] model1:{:.4f}, model2:{:.4f}, model3:{:.4f} -> ensemble:{:.4f}\".format(\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred1\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred2\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[\"pred3\"]),\n",
    "        roc_auc_score(input_df[\"true\"], input_df[col_pred]),\n",
    "    ))\n",
    "\n",
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641b38a",
   "metadata": {
    "papermill": {
     "duration": 0.104086,
     "end_time": "2024-02-14T12:58:17.290956",
     "exception": false,
     "start_time": "2024-02-14T12:58:17.186870",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-33: 推論時のアンサンブル処理と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96951f2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:17.499278Z",
     "iopub.status.busy": "2024-02-14T12:58:17.498822Z",
     "iopub.status.idle": "2024-02-14T12:58:17.514816Z",
     "shell.execute_reply": "2024-02-14T12:58:17.513415Z"
    },
    "papermill": {
     "duration": 0.122226,
     "end_time": "2024-02-14T12:58:17.517349",
     "exception": false,
     "start_time": "2024-02-14T12:58:17.395123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9396\n"
     ]
    }
   ],
   "source": [
    "df_test[\"pred_ensemble1\"] = (df_test[\"pred1\"] + df_test[\"pred2\"] + df_test[\"pred3\"]) / 3\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14646cf",
   "metadata": {
    "papermill": {
     "duration": 0.100762,
     "end_time": "2024-02-14T12:58:17.720596",
     "exception": false,
     "start_time": "2024-02-14T12:58:17.619834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6.3.2 重み付き平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db00a7",
   "metadata": {
    "papermill": {
     "duration": 0.102666,
     "end_time": "2024-02-14T12:58:17.923967",
     "exception": false,
     "start_time": "2024-02-14T12:58:17.821301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-34: 重み付き平均によるアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c195ff4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:18.130011Z",
     "iopub.status.busy": "2024-02-14T12:58:18.129400Z",
     "iopub.status.idle": "2024-02-14T12:58:18.148415Z",
     "shell.execute_reply": "2024-02-14T12:58:18.147259Z"
    },
    "papermill": {
     "duration": 0.124813,
     "end_time": "2024-02-14T12:58:18.150973",
     "exception": false,
     "start_time": "2024-02-14T12:58:18.026160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.3 0.4]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.811455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.275091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.433324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.215643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.511209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble2\n",
       "0     1  0.683821  0.874443  0.859939        0.811455\n",
       "1     0  0.540691  0.113419  0.197144        0.275091\n",
       "2     0  0.310541  0.334798  0.599304        0.433324\n",
       "3     0  0.043486  0.170622  0.378528        0.215643\n",
       "4     0  0.550847  0.354703  0.598860        0.511209"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = [0.3, 0.3, 0.4]\n",
    "weight = weight / np.sum(weight)\n",
    "print(weight)\n",
    "\n",
    "df_train[\"pred_ensemble2\"] = df_train[\"pred1\"] * weight[0] + \\\n",
    "                             df_train[\"pred2\"] * weight[1] + \\\n",
    "                             df_train[\"pred3\"] * weight[2]\n",
    "df_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble2\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfba442",
   "metadata": {
    "papermill": {
     "duration": 0.104315,
     "end_time": "2024-02-14T12:58:18.357366",
     "exception": false,
     "start_time": "2024-02-14T12:58:18.253051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-35: アンサンブルの精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1aa4d001",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:18.628880Z",
     "iopub.status.busy": "2024-02-14T12:58:18.628446Z",
     "iopub.status.idle": "2024-02-14T12:58:18.642943Z",
     "shell.execute_reply": "2024-02-14T12:58:18.641189Z"
    },
    "papermill": {
     "duration": 0.186616,
     "end_time": "2024-02-14T12:58:18.645885",
     "exception": false,
     "start_time": "2024-02-14T12:58:18.459269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9614\n"
     ]
    }
   ],
   "source": [
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8115cb6a",
   "metadata": {
    "papermill": {
     "duration": 0.101403,
     "end_time": "2024-02-14T12:58:18.850520",
     "exception": false,
     "start_time": "2024-02-14T12:58:18.749117",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-36: 推論時のアンサンブル処理と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e541381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:19.058825Z",
     "iopub.status.busy": "2024-02-14T12:58:19.058025Z",
     "iopub.status.idle": "2024-02-14T12:58:19.076163Z",
     "shell.execute_reply": "2024-02-14T12:58:19.074771Z"
    },
    "papermill": {
     "duration": 0.126801,
     "end_time": "2024-02-14T12:58:19.079175",
     "exception": false,
     "start_time": "2024-02-14T12:58:18.952374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9420\n"
     ]
    }
   ],
   "source": [
    "df_test[\"pred_ensemble2\"] = df_test[\"pred1\"] * weight[0] + \\\n",
    "                            df_test[\"pred2\"] * weight[1] + \\\n",
    "                            df_test[\"pred3\"] * weight[2]\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad3e16",
   "metadata": {
    "papermill": {
     "duration": 0.103004,
     "end_time": "2024-02-14T12:58:19.285302",
     "exception": false,
     "start_time": "2024-02-14T12:58:19.182298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6.3.3 スタッキング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fd509",
   "metadata": {
    "papermill": {
     "duration": 0.102093,
     "end_time": "2024-02-14T12:58:19.491665",
     "exception": false,
     "start_time": "2024-02-14T12:58:19.389572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-37: スタッキングによるアンサンブル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9099b4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:19.701156Z",
     "iopub.status.busy": "2024-02-14T12:58:19.700721Z",
     "iopub.status.idle": "2024-02-14T12:58:19.762964Z",
     "shell.execute_reply": "2024-02-14T12:58:19.761343Z"
    },
    "papermill": {
     "duration": 0.172318,
     "end_time": "2024-02-14T12:58:19.766094",
     "exception": false,
     "start_time": "2024-02-14T12:58:19.593776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred_ensemble3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.683821</td>\n",
       "      <td>0.874443</td>\n",
       "      <td>0.859939</td>\n",
       "      <td>0.745020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.540691</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.197144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.310541</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.599304</td>\n",
       "      <td>0.206734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.043486</td>\n",
       "      <td>0.170622</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.354703</td>\n",
       "      <td>0.598860</td>\n",
       "      <td>0.303498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   true     pred1     pred2     pred3  pred_ensemble3\n",
       "0     1  0.683821  0.874443  0.859939        0.745020\n",
       "1     0  0.540691  0.113419  0.197144        0.000000\n",
       "2     0  0.310541  0.334798  0.599304        0.206734\n",
       "3     0  0.043486  0.170622  0.378528        0.000000\n",
       "4     0  0.550847  0.354703  0.598860        0.303498"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "x, y = df_train[[\"pred1\", \"pred2\", \"pred3\"]], df_train[[\"true\"]]\n",
    "oof = np.zeros(len(x))\n",
    "models = []\n",
    "\n",
    "cv = list(StratifiedKFold(n_splits=5, shuffle=True, random_state=123).split(x, y))\n",
    "for nfold in np.arange(5):\n",
    "    # 学習データと検証データの分離\n",
    "    idx_tr, idx_va = cv[nfold][0], cv[nfold][1]\n",
    "    x_tr, y_tr = x.loc[idx_tr, :], y.loc[idx_tr, :]\n",
    "    x_va, y_va = x.loc[idx_va, :], y.loc[idx_va, :]\n",
    "    \n",
    "    # モデル学習\n",
    "    model = Lasso(alpha=0.01)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    models.append(model)\n",
    "    \n",
    "    # 検証データの予測値算出\n",
    "    y_va_pred = model.predict(x_va)\n",
    "    oof[idx_va] = y_va_pred\n",
    "    \n",
    "df_train[\"pred_ensemble3\"] = oof\n",
    "df_train[\"pred_ensemble3\"] = df_train[\"pred_ensemble3\"].clip(lower=0, upper=1)\n",
    "df_train[[\"true\",\"pred1\",\"pred2\",\"pred3\",\"pred_ensemble3\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161c111",
   "metadata": {
    "papermill": {
     "duration": 0.103026,
     "end_time": "2024-02-14T12:58:19.971151",
     "exception": false,
     "start_time": "2024-02-14T12:58:19.868125",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-38: アンサンブルの精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b9fbd7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:20.183644Z",
     "iopub.status.busy": "2024-02-14T12:58:20.182930Z",
     "iopub.status.idle": "2024-02-14T12:58:20.195671Z",
     "shell.execute_reply": "2024-02-14T12:58:20.194485Z"
    },
    "papermill": {
     "duration": 0.120483,
     "end_time": "2024-02-14T12:58:20.198478",
     "exception": false,
     "start_time": "2024-02-14T12:58:20.077995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8342, model2:0.8671, model3:0.9050 -> ensemble:0.9577\n"
     ]
    }
   ],
   "source": [
    "evaluate_ensemble(df_train, col_pred=\"pred_ensemble3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec4c31",
   "metadata": {
    "papermill": {
     "duration": 0.102582,
     "end_time": "2024-02-14T12:58:20.403935",
     "exception": false,
     "start_time": "2024-02-14T12:58:20.301353",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### スクリプト6-39: 推論時のアンサンブル処理と、精度評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "baa4ada2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-14T12:58:20.610249Z",
     "iopub.status.busy": "2024-02-14T12:58:20.609843Z",
     "iopub.status.idle": "2024-02-14T12:58:20.644268Z",
     "shell.execute_reply": "2024-02-14T12:58:20.642643Z"
    },
    "papermill": {
     "duration": 0.140976,
     "end_time": "2024-02-14T12:58:20.647119",
     "exception": false,
     "start_time": "2024-02-14T12:58:20.506143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[auc] model1:0.8086, model2:0.8398, model3:0.8973 -> ensemble:0.9437\n"
     ]
    }
   ],
   "source": [
    "df_test[\"pred_ensemble3\"] = 0\n",
    "for model in models:\n",
    "    df_test[\"pred_ensemble3\"] += model.predict(df_test[[\"pred1\", \"pred2\", \"pred3\"]]) / len(models)\n",
    "df_test[\"pred_ensemble3\"] = df_test[\"pred_ensemble3\"].clip(lower=0, upper=1)\n",
    "evaluate_ensemble(df_test, col_pred=\"pred_ensemble3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ed40f",
   "metadata": {
    "papermill": {
     "duration": 0.103363,
     "end_time": "2024-02-14T12:58:20.853577",
     "exception": false,
     "start_time": "2024-02-14T12:58:20.750214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5acf1ec",
   "metadata": {
    "papermill": {
     "duration": 0.109538,
     "end_time": "2024-02-14T12:58:21.066076",
     "exception": false,
     "start_time": "2024-02-14T12:58:20.956538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 26502,
     "sourceId": 3136,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 207.333379,
   "end_time": "2024-02-14T12:58:24.381445",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-14T12:54:57.048066",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
